{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Gaussian Parameters in 2D for Synthetic Data and Image\n",
    "\n",
    "In this notebook, we'll be optimizing for 2D Gaussians to represent images, while building up the intuition that generalizes to 3D Gaussian Splatting. \n",
    "\n",
    "In Part 0, we'll create the building blocks for Gaussian representations.\n",
    "In Part 1, we'll be targeting a \"synthetic\" image (originally reconstructed from Gaussians).\n",
    "In Part 2, we'll be optimizing for an actual target image.\n",
    "In Part 3, we'll move our optimized target image representation to the GLSL shader to view our animated optimization.\n",
    "\n",
    "For inspiration, here are a couple of cool examples on shadertoy of what you could do with your 2D Gaussian image once you work through this notebook:\n",
    "- [https://www.shadertoy.com/view/tflXRB](https://www.shadertoy.com/view/tflXRB)\n",
    "- [https://www.shadertoy.com/view/dtSfDD](https://www.shadertoy.com/view/dtSfDD)\n",
    "- [https://www.shadertoy.com/view/MdfGDH](https://www.shadertoy.com/view/MdfGDH)\n",
    "- [https://www.shadertoy.com/view/4df3D8](https://www.shadertoy.com/view/4df3D8)\n",
    "- [https://www.shadertoy.com/view/4XXSDN](https://www.shadertoy.com/view/4XXSDN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:24.152235Z",
     "start_time": "2025-03-13T01:20:23.077945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "\n",
    "# Visu\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# file i/o\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# For assembling video\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Misc.\n",
    "from typing import Union\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm  # progress bar\n",
    "TIME_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "# Check if notebook is running on a Google Colab\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:24.174918Z",
     "start_time": "2025-03-13T01:20:24.153639Z"
    }
   },
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:24.194296Z",
     "start_time": "2025-03-13T01:20:24.167558Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps backend (torch.device)\n"
     ]
    }
   ],
   "source": [
    "# Choose between available PyTorch backends. Use GPU if available.\n",
    "DEVICE = torch.device('cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")  # Metal backend for Apple devices\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')  # Cuda backend for Nvidia GPUs\n",
    "    \n",
    "print(f\"Using {DEVICE} backend (torch.device)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Helper classes and functions\n",
    "\n",
    "You don't need to touch anything here. \n",
    "They are included here only to make the notebook self-contained, and include the following functionalities used in throughout the notebook:\n",
    "- Domain2D: handles the 2D domain and its discretization\n",
    "- Simplify handling input/output paths and filenames \n",
    "- Plotting helper functions\n",
    "- Very simple Timer class\n",
    "- Writing out parameters as JSON and assembling video\n",
    "\n",
    "If you're curious, feel free to dig in, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:24.194943Z",
     "start_time": "2025-03-13T01:20:24.184786Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@title Domain2D\n",
    "class Domain2D:\n",
    "    \"\"\"\n",
    "    Helper function for handling a 2D domain, discretized on a grid of given resolution.\n",
    "    \"\"\"\n",
    "    x_dim: tuple[float]\n",
    "    y_dim: tuple[float]\n",
    "    res_x: float\n",
    "    res_y: float\n",
    "    xx: torch.Tensor\n",
    "    yy: torch.Tensor\n",
    "\n",
    "    def __init__(self, x_dim, y_dim, res_x, res_y):\n",
    "        self.x_dim, self.y_dim = x_dim, y_dim\n",
    "        self.res_x, self.res_y = res_x, res_y\n",
    "\n",
    "        self.xx, self.yy = torch.meshgrid(\n",
    "            torch.linspace(self.x_dim[0], self.x_dim[1], self.res_x, device=DEVICE),\n",
    "            torch.linspace(self.y_dim[0], self.y_dim[1], self.res_y, device=DEVICE),\n",
    "            indexing='xy'\n",
    "        )\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"Domain2D: {self.x_dim}x{self.y_dim} \"\n",
    "                f\"discretized on a {self.res_x}x{self.res_y} grid.\")\n",
    "    \n",
    "    def get_extent(self):\n",
    "        extent = (*self.x_dim, *self.y_dim)\n",
    "        return extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:24.213178Z",
     "start_time": "2025-03-13T01:20:24.192617Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@title Files and folders\n",
    "\n",
    "CURRENT_SCENE = datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "DATA_FOLDER = pathlib.Path(\"data\")\n",
    "CURRENT_SCENE_FOLDER = DATA_FOLDER / pathlib.Path(CURRENT_SCENE)\n",
    "LAST_FILE_NAME = 0\n",
    "\n",
    "def save_fig_to_file(fig):\n",
    "    # Save plot to file as {curr_date}/{epoch}.jpg\n",
    "    global LAST_FILE_NAME\n",
    "    curr_image_file = CURRENT_SCENE_FOLDER / f\"{LAST_FILE_NAME}.jpg\"\n",
    "    fig.savefig(curr_image_file.absolute())\n",
    "    \n",
    "    LAST_FILE_NAME += 1\n",
    "    \n",
    "def initialize_file_names():\n",
    "    \"\"\"\n",
    "    Update current folder name and reset file names.\n",
    "    We might want to call this when a new optimization run starts.\n",
    "    \"\"\"\n",
    "    global LAST_FILE_NAME, CURRENT_SCENE, CURRENT_SCENE_FOLDER\n",
    "    \n",
    "    CURRENT_SCENE = datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    CURRENT_SCENE_FOLDER = DATA_FOLDER / pathlib.Path(CURRENT_SCENE)\n",
    "    \n",
    "    CURRENT_SCENE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "    LAST_FILE_NAME = 0\n",
    "    \n",
    "initialize_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:24.225955Z",
     "start_time": "2025-03-13T01:20:24.200857Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@title Plotting\n",
    "\n",
    "def plot_tensor_image(\n",
    "        image,\n",
    "        title: str = \"\",\n",
    "        _plt=plt,\n",
    "        extent=None,\n",
    "):\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.cpu().detach().numpy()\n",
    "\n",
    "    if image.shape[-1] == 3:\n",
    "        image = np.clip(image, 0, 1)\n",
    "        # plot (R,G,B) image\n",
    "        #  Clip image colors\n",
    "        \n",
    "    _plt.imshow(\n",
    "        image,\n",
    "        extent=extent,  # (left, right, bottom, top)\n",
    "        origin=\"lower\"\n",
    "    )\n",
    "\n",
    "    if _plt == plt:\n",
    "        _plt.title(title)\n",
    "    else:\n",
    "        _plt.title.set_text(title)\n",
    "\n",
    "\n",
    "def draw_outline(params, _plt=plt):\n",
    "    centers, sigmas, thetas = params[\"centers\"], params[\"sigmas\"], params[\"thetas\"]\n",
    "    # Convert to basic numpy array if necessary,\n",
    "    # bringing tensors to the cpu and detach from computing graph\n",
    "    if isinstance(centers, torch.Tensor):\n",
    "        centers = centers.cpu().detach().numpy()\n",
    "    if isinstance(sigmas, torch.Tensor):\n",
    "        sigmas = sigmas.cpu().detach().numpy()\n",
    "    if isinstance(thetas, torch.Tensor):\n",
    "        thetas = thetas.cpu().detach().numpy()\n",
    "\n",
    "    if not isinstance(_plt, plt.Axes):\n",
    "        _plt = _plt.gca()\n",
    "\n",
    "    # plot centers as red dots\n",
    "    _plt.scatter(x=centers[:, 0], y=centers[:, 1], c='r', s=1)\n",
    "\n",
    "    # draw ellipses\n",
    "    for i, c in enumerate(centers):\n",
    "        _plt.add_patch(\n",
    "            Ellipse(\n",
    "                (c[0], c[1]),\n",
    "                width=sigmas[i][0] * 3.5,\n",
    "                height=sigmas[i][1] * 3.5,\n",
    "                angle=thetas[i] * (180.0 / np.pi),\n",
    "                edgecolor='red',\n",
    "                facecolor='none',\n",
    "                linewidth=1,\n",
    "                alpha=1.0\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def assemble_plot_data(data, outline_params):\n",
    "    \"\"\"\n",
    "    Make the data ready for plotting with the `plot` function.\n",
    "    Calculates the number of rows and columns to be plotted based on the supplied data.\n",
    "\n",
    "    :param data: image data, or iterable of image data\n",
    "    :param outline_params: gaussian parameters used for plotting an overlay over the reconstructed image\n",
    "    :return: number of columns (int), rows (int), assembled data (np.ndarray) and outline parameters (list)\n",
    "    \"\"\"\n",
    "\n",
    "    def is_iterable(x):\n",
    "        return isinstance(x, list) or isinstance(x, tuple)\n",
    "\n",
    "    def is_2d_iterable(x):\n",
    "        return isinstance(x[0], list) or isinstance(x[0], tuple)\n",
    "\n",
    "    def get_numpy_data(d):\n",
    "        # Takes a single piece of plottable data, and makes it a numpy array\n",
    "        if isinstance(d, torch.Tensor):\n",
    "            d = d.cpu().detach().numpy()\n",
    "        d = np.array(d)\n",
    "        return d\n",
    "\n",
    "    # Create a 2D array of plottable data [[row_1_1, row_1_2 ...],[row_2_1, row_2_2, ...], ...]\n",
    "    # Each piece of data is uniformly converted to a numpy array\n",
    "    new_data = []\n",
    "    if is_iterable(data):\n",
    "        if is_2d_iterable(data):\n",
    "            for i in range(len(data)):\n",
    "                curr_row = []\n",
    "                for j in range(len(data[i])):\n",
    "                    curr_data = get_numpy_data(data[i][j])\n",
    "                    curr_row.append(curr_data)\n",
    "                new_data.append(curr_row)\n",
    "        else:\n",
    "            single_row = []\n",
    "            for i in range(len(data)):\n",
    "                curr_data = get_numpy_data(data[i])\n",
    "                single_row.append(curr_data)\n",
    "            new_data.append(single_row)\n",
    "    else:\n",
    "        # Single piece of data, but we still create a 2D array\n",
    "        new_data.append([get_numpy_data(data)])\n",
    "\n",
    "    data = new_data\n",
    "\n",
    "    # Calculate number of rows and columns in the plot\n",
    "    nrows = len(data)\n",
    "    ncols = len(data[0])\n",
    "\n",
    "    # Handle outline_params\n",
    "    if isinstance(outline_params, dict):\n",
    "        # If plotting only a single piece of data\n",
    "        assert ncols == nrows == 1, \"Non-list outline params is only allowed for plotting a single data.\"\n",
    "        outline_params = [[outline_params]]\n",
    "    if outline_params is not None:\n",
    "        if not all(p is None for p in outline_params):\n",
    "            if not isinstance(outline_params[0], list):\n",
    "                # If not already a 2D array, then\n",
    "                # wrap outline_params to be a 2D array for [row][col] indexing\n",
    "                outline_params = [outline_params]\n",
    "        else:\n",
    "            outline_params = None\n",
    "\n",
    "    # We could assert that outline_params should be None, or having the same shape as the data\n",
    "\n",
    "    return ncols, nrows, data, outline_params\n",
    "\n",
    "\n",
    "def assemble_titles(title, ncols, nrows):\n",
    "    \"\"\"\n",
    "    :param title: string or list of strings\n",
    "    :param ncols: number of columns in the plot\n",
    "    :param nrows: number of rows in the plot\n",
    "    :return: a 2D list of titles corresponding to a (ncols, nrows) plot.\n",
    "    \"\"\"\n",
    "    if isinstance(title, (tuple, list, dict)):\n",
    "        if isinstance(title[0], (tuple, list, dict)):\n",
    "            # Title is a 2D array of titles for each subplot, individually\n",
    "            assert len(title) == nrows and len(title[0]) == ncols\n",
    "        else:\n",
    "            # Wrap 1D list of titles to be a 2D array for a single row\n",
    "            title = [title]\n",
    "    else:\n",
    "        # Same title for each subplot\n",
    "        title = [[title] * ncols] * nrows\n",
    "\n",
    "    return title\n",
    "\n",
    "\n",
    "def plot(\n",
    "        data: Union[torch.Tensor, list, tuple, np.ndarray],\n",
    "        title: Union[str, list] = \"\",\n",
    "        figsize=(16, 6),\n",
    "        extent=None,\n",
    "        domain: Domain2D = None,  # if domain is not None, then it overwrite extent, xx and yy\n",
    "        outline_params=None,\n",
    "        show_plot=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Main plotting function.\n",
    "    \"\"\"\n",
    "    ncols, nrows, data, outline_params = assemble_plot_data(data, outline_params)\n",
    "    titles = assemble_titles(title, ncols, nrows)\n",
    "\n",
    "    # Shape of axs, and existence of dimensions is dependent on number of rows and columns. If figure is (1,1)\n",
    "    # or either ncols or nrows is 1, then at least 1 of the dimensions will be missing from the axs list.\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "\n",
    "    # Make sure that axs is a 2D list of all subplot axes which can be indexed as `axs[row_i][col_j]`.\n",
    "    if nrows == ncols == 1:\n",
    "        axs = [[axs]]\n",
    "    elif nrows == 1:\n",
    "        axs = [axs]  # axs is a 1D list\n",
    "    elif ncols == 1:\n",
    "        axs = [[axs[i]] for i in range(len(axs))]  # axs is a 1D list, but we have to reshape it\n",
    "\n",
    "    # Set extent, xx and yy from domain if it was supplied\n",
    "    if domain is not None:\n",
    "        extent = domain.get_extent()\n",
    "\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            curr_data = data[i][j]\n",
    "            curr_ax = axs[i][j]\n",
    "            curr_title = titles[i][j]\n",
    "\n",
    "            if len(curr_data.shape) > 1:\n",
    "                # Plot scalar field or image data\n",
    "                plot_tensor_image(\n",
    "                    image=curr_data,\n",
    "                    title=curr_title,\n",
    "                    _plt=curr_ax,\n",
    "                    extent=extent,\n",
    "                )\n",
    "                if outline_params is not None and outline_params[i][j] is not None:\n",
    "                    draw_outline(params=outline_params[i][j], _plt=curr_ax)\n",
    "                curr_ax.set_aspect('equal')\n",
    "            elif len(curr_data.shape) == 1:\n",
    "                # Plot 1D data, e.g. loss curve\n",
    "                curr_ax.plot(curr_data)\n",
    "                curr_ax.set_xticks(range(0, len(curr_data), math.ceil(len(curr_data) / 8)))\n",
    "                curr_ax.set_title('Learning curve')\n",
    "                curr_ax.set_xlabel('Epoch')\n",
    "                curr_ax.set_ylabel('Loss')\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:24.226764Z",
     "start_time": "2025-03-13T01:20:24.214905Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@title Timer\n",
    "class Timer:\n",
    "    \"\"\"\n",
    "    Super simple utility class for displaying elapsed time.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.init_time = datetime.now()\n",
    "        # Step 1: Print the current time\n",
    "        print(\"Current time:\", self.init_time.strftime(TIME_FORMAT))\n",
    "\n",
    "    def print_time(self, reset_time = False):\n",
    "        # Print the time and the time elapsed since init_time\n",
    "        current_time = datetime.now()\n",
    "        elapsed_time = current_time - self.init_time\n",
    "\n",
    "        print(\"Current time:\", current_time.strftime(TIME_FORMAT))\n",
    "        print(\"Time elapsed:\", str(elapsed_time))\n",
    "\n",
    "        # Optionally overwrite initial time\n",
    "        if reset_time:\n",
    "            self.init_time = current_time\n",
    "\n",
    "    def get_elapsed_time(self) -> str:\n",
    "        delta_time = datetime.now() - self.init_time\n",
    "        return \"{:02}:{:02}:{:02}\".format(\n",
    "                delta_time.seconds // 3600,\n",
    "                (delta_time.seconds % 3600) // 60,\n",
    "                (delta_time.seconds % 60) // 1,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:24.245456Z",
     "start_time": "2025-03-13T01:20:24.225408Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@title Misc.: json i/o and video\n",
    "\n",
    "def gaussians_from_json_file(filename):\n",
    "    filepath = pathlib.Path(filename)\n",
    "    filepath = CURRENT_SCENE_FOLDER / filepath\n",
    "\n",
    "    json_data = dict()\n",
    "\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        # TODO check for invalid input data here\n",
    "\n",
    "        json_data['gaussians'] = dict()\n",
    "        json_data['gaussians']['alphas']  = data['alphas']\n",
    "        json_data['gaussians']['centers'] = data['centers']\n",
    "        json_data['gaussians']['sigmas']  = data['sigmas']\n",
    "        json_data['gaussians']['thetas']  = data['thetas']\n",
    "\n",
    "        json_data['N']     = data['N']\n",
    "        json_data['dims']  = data['dims']\n",
    "        json_data['x_dim'] = data['x_dim']\n",
    "        json_data['y_dim'] = data['y_dim']\n",
    "        json_data['res_x'] = data['res_x']\n",
    "        json_data['res_y'] = data['res_y']\n",
    "\n",
    "    print(f\"Read gaussian scene from {filepath} with \"\n",
    "          f\"N={json_data['N']}, dims={json_data['dims']}, gaussians#={len(json_data['gaussians'])}\"\n",
    "          f\"#alphas={len(json_data['gaussians']['alphas'])}, \"\n",
    "          f\"#centers={len(json_data['gaussians']['centers'])}, \"\n",
    "          f\"#sigmas={len(json_data['gaussians']['sigmas'])}, \"\n",
    "          f\"#thetas={len(json_data['gaussians']['thetas'])}\")\n",
    "\n",
    "    return json_data\n",
    "\n",
    "\n",
    "def gaussians_to_json_file(filename, params, domain):\n",
    "    \"\"\"\n",
    "    filename: relative to the current scene\n",
    "    \"\"\"\n",
    "    filepath = CURRENT_SCENE_FOLDER / filename\n",
    "\n",
    "    # Convert PyTorch tensors to Python floats (and lists of them)\n",
    "    alphas_item = [[x.item() for x in a] for a in params['alphas']]\n",
    "    centers_item = [[x.item() for x in c] for c in params['centers']]\n",
    "    sigmas_item = [[x.item() for x in s] for s in params['sigmas']]\n",
    "    # Can't array comprehend over 0D tensor\n",
    "    thetas_item = [t.item() for t in params['thetas']]\n",
    "\n",
    "    scene_data = {\n",
    "        \"x_dim\": domain.x_dim,\n",
    "        \"y_dim\": domain.y_dim,\n",
    "        \"res_x\": domain.res_x,\n",
    "        \"res_y\": domain.res_y,\n",
    "        \"N\": params['alphas'].shape[0],\n",
    "        \"dims\": params['alphas'].shape[-1],\n",
    "        \"alphas\": alphas_item,\n",
    "        \"centers\": centers_item,\n",
    "        \"sigmas\": sigmas_item,\n",
    "        \"thetas\": thetas_item\n",
    "    }\n",
    "\n",
    "    with open(filepath, 'w') as file:\n",
    "        json.dump(scene_data, file, indent=2)\n",
    "\n",
    "    print(f\"2D Gaussian Scene written to {filepath}.\")\n",
    "    \n",
    "    \n",
    "def assemble_video(image_folder: str, output_file: str=\"video.mp4\", fps=10):\n",
    "    \"\"\"\n",
    "    image_folder: absolute path\n",
    "    output_file: name of output file\n",
    "    \"\"\"\n",
    "    image_files = sorted(glob.glob(f\"{image_folder}/*.jpg\"), key=lambda x: int(Path(x).stem))\n",
    "    if not image_files:\n",
    "        raise ValueError(\"No .jpg files found in the specified directory.\")\n",
    "\n",
    "    # Read the first image to get the dimensions\n",
    "    image_0 = cv2.imread(image_files[0])\n",
    "    height, width, layers = image_0.shape\n",
    "\n",
    "    # Adjust FPS based on the number of images\n",
    "    if len(image_files) > 200:\n",
    "        fps = 30\n",
    "    elif len(image_files) > 100:\n",
    "        fps = 20\n",
    "\n",
    "    # Create Video Writer with proper codec\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'FMP4')  # Using H.264 codec\n",
    "    video = cv2.VideoWriter(output_file, fourcc, fps, (width, height))\n",
    "\n",
    "    # Write frames to video\n",
    "    for image_file in image_files:\n",
    "        video.write(cv2.imread(image_file))\n",
    "\n",
    "    video.release()\n",
    "    print(f\"Video saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 0: 2D Gaussian Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A 2D Gaussian is parameterized by:\n",
    "- centers $c = [c_x, c_y]^T$\n",
    "- scales $\\sigma = [\\sigma_x, \\sigma_y]^T$\n",
    "- scalar rotation $\\theta$ (Note: we could also use a unit-length complex number in the spirit of using quaternions in 3D, but a scalar rotation is perfectly fine.) \n",
    "\n",
    "Its value at point $\\bf{p}$ is given by\n",
    "$$\n",
    "f(p) = \\text{exp}\\left(\n",
    "  -\\frac{1}{2} \n",
    "  (p - c)^T \n",
    "  \\Sigma^{-1}\n",
    "  (p - c)\n",
    "\\right),\n",
    "$$\n",
    "\n",
    "where the covariance matrix $\\Sigma$ describes the shape of the Gaussian, and we build it as\n",
    "\n",
    "$$\n",
    "\\Sigma = \n",
    "      RSS^TR^T,\n",
    "$$\n",
    "\n",
    "making use of (1) $(AB)^{-1} = B^{-1} A^{-1}$, and (2) $R^{-1} = R^T$ for rotational matrices, we have\n",
    "$$\n",
    "\\Sigma^{-1} = R(SS^{T})^{-1}R^T.\n",
    "$$\n",
    "\n",
    "If we want to write out our 2D Gaussian function explicitly, we have:\n",
    "\n",
    "$$\n",
    "f\\left(\\begin{bmatrix}\n",
    "    p_x\\\\\n",
    "    p_y\n",
    "\\end{bmatrix}\\right) \n",
    "= \\text{exp}\\left(\n",
    "    -\\frac{1}{2} \n",
    "    \\begin{bmatrix}\n",
    "        p_x - c_x &\n",
    "        p_y - c_y\n",
    "    \\end{bmatrix}\n",
    "    \\Sigma^{-1}\n",
    "    \\begin{bmatrix}\n",
    "        p_x - c_x\\\\\n",
    "        p_y - c_y\n",
    "    \\end{bmatrix}\n",
    "\\right),\n",
    "$$ \n",
    "\n",
    "where\n",
    "$$\n",
    "    \\Sigma^{-1} = \n",
    "      \\begin{bmatrix}\n",
    "        \\cos \\theta & -\\sin\\theta\\\\\n",
    "        \\sin \\theta & \\cos \\theta\n",
    "      \\end{bmatrix}\n",
    "      \\begin{bmatrix}\n",
    "        \\frac{1}{\\sigma_x^2} & 0 \\\\\n",
    "        0 & \\frac{1}{\\sigma_y^2}\n",
    "      \\end{bmatrix}\n",
    "      \\begin{bmatrix}\n",
    "        \\cos \\theta & \\sin\\theta\\\\\n",
    "        -\\sin \\theta & \\cos \\theta\n",
    "      \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "To reconstruct a 2D image, we add together function of this form, but also multiply them by an \"alpha\" channel. In the original 3DGS implementation, they use a Gaussian-wise $\\alpha \\in \\mathbb{R}$ and RGB color $[c_r, c_g, c_b] \\in \\mathbb{R}^3$ (converted from spherical harmonics in 3D, given our current view direction).\n",
    "\n",
    "To simplify things here, we multiply these together, and store $\\boldsymbol{\\alpha} = \\alpha \\cdot [ c_r, c_g, c_b ]$ for each Gaussian.\n",
    "\n",
    "Thus, we reconstruct each pixel $\\textbf{p}$ of our 2D image $\\textbf{I}$ by summing together to contribution from N Gaussians as \n",
    "\n",
    "$$\n",
    "I(p) = \\sum_{i=1}^{N} \\boldsymbol{\\alpha}_i f_i(p).\n",
    "$$\n",
    "\n",
    "This is already implemented in `reconstruct_gaussian_2d` below, with two helper functions: `build_sigma_invs` and `build_position_tensor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0.1: Build The Inverse Covariance Matrix\n",
    "\n",
    "Here, you will build the inverse covariance matrix for a single 2D Gaussian, using the provided rotation and scale vector. \n",
    "In order to do this, you must build the rotation matrix R and the diagonal inverse scaling matrix D (seen above as (SS^T))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:24.263347Z",
     "start_time": "2025-03-13T01:20:24.234937Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_single_sigma_inv(theta: torch.Tensor, sigma: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the inverse covariance matrix for a single 2D Gaussian,\n",
    "    given a rotation (theta) and a scale vector (sigma).\n",
    "\n",
    "    theta: shape (1), a scalar tensor representing the rotation angle.\n",
    "    sigma: shape (2) a tensor representing the scales in x and y directions.\n",
    "\n",
    "    Returns:\n",
    "        A 2x2 tensor representing the inverse covariance matrix.\n",
    "    \"\"\"\n",
    "    # Construct the 2x2 rotation matrix R.\n",
    "    R = torch.eye(2, device=DEVICE)  # create a 2x2 matrix\n",
    "    # Populate the elements of this matrix using R[row, column] indexing.\n",
    "\n",
    "    ########## \n",
    "    # BEGINNING OF YOUR CODE.\n",
    "    ##########\n",
    "    \n",
    "    \n",
    "\n",
    "    ########## \n",
    "    # END OF YOUR CODE\n",
    "    ##########\n",
    "\n",
    "    # Construct the 2x2 diagonal inverse scaling matrix.\n",
    "    # Here, sigma is assumed to be a vector: [sigma_x, sigma_y].\n",
    "    \n",
    "    D = torch.eye(2, device=DEVICE)  # 2x2 identity matrix\n",
    "    # Hint: How should you tweak the elements of a 2x2 identity matrix to scale it by sigma? \n",
    "    \n",
    "    # Make sure that sigma**2 is not zero to avoid division by zero.\n",
    "    sigma_sqare_safe = sigma**2 + 1e-6\n",
    "    ########## \n",
    "    # BEGINNING OF YOUR CODE\n",
    "    ##########\n",
    "    \n",
    "    \n",
    "    \n",
    "    ########## \n",
    "    # END OF YOUR CODE\n",
    "    ##########\n",
    "\n",
    "    # Compute the inverse covariance matrix: sigma_inv = R @ D @ R.T\n",
    "    sigma_inv = R @ D @ R.T\n",
    "    return sigma_inv\n",
    "\n",
    "\n",
    "def build_position_tensor(p_x: torch.Tensor, p_y: torch.Tensor, center: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Construct a tensor of relative positions for a single Gaussian,\n",
    "    given grid coordinates and a 2D center.\n",
    "\n",
    "    p_x: (res_y, res_x) of x-coordinates of the grid (image pixel) positions.\n",
    "    p_y: (res_y, res_x) of y-coordinates of the grid (image pixel) positions.\n",
    "    center: A tensor with the Gaussian center (shape: [2]).\n",
    "\n",
    "    A tensor of relative positions with shape [res_y, res_x, 2].\n",
    "    \"\"\"\n",
    "    # Combine the x and y coordinates into and [res_y, res_x, 2] grid.\n",
    "    p_grid = torch.stack([p_x, p_y], dim=-1)\n",
    "    # Subtract the center to obtain relative positions.\n",
    "    pos = p_grid - center\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0.2: Accumulate contribution of Gaussians for image field\n",
    "\n",
    "Here, you will reconstruct the image by sampling multiple 2D Gaussians over a given 2D domain.\n",
    "\n",
    "In order to do this for each gaussian, you must apply the inverse covariance matrix to the Gaussian's position to get the transformed position and apply the function f(p) to the transformed position as seen in the equation block above. \n",
    "\n",
    "Finally, you must multiply the alpha of the gaussian by the gaussian's contribution value f(p) to get the weighted contribution of this Gaussian that can be added to the image field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reconstruct_image(params: dict, domain) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Sample multiple 2D Gaussians over a given 2D domain in a non-batched manner.\n",
    "    Each Gaussian is defined by its alpha (rgb colors*opacity), center, sigma (scale) and theta (rotation).\n",
    "    The final field (rgb image) is the sum of the contributions of each Gaussian.\n",
    "\n",
    "    Returns:\n",
    "        A tensor representing the aggregated image (shape: [res_x, res_y, 3]).\n",
    "    \"\"\"\n",
    "    alphas = params['alphas']  # shape (N, 3)\n",
    "    centers = params['centers']  # shape (N, 2)\n",
    "    sigmas = params['sigmas']  # shape (N, 2)\n",
    "    thetas = params['thetas']  # shape (N)\n",
    "    \n",
    "    N = alphas.shape[0]\n",
    "    # (res_x, res_y, 3)-shaped image with RGB colors.\n",
    "    field = torch.zeros((domain.xx.shape[0], domain.xx.shape[1], 3), dtype=torch.float32, device=DEVICE)\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Compute the inverse covariance matrix for the i-th Gaussian.\n",
    "        sigma_inv = build_single_sigma_inv(thetas[i], sigmas[i])\n",
    "        \n",
    "        # Build the position tensor relative to the i-th Gaussian's center.\n",
    "        pos = build_position_tensor(domain.xx, domain.yy, centers[i])\n",
    "        \n",
    "        # Compute the quadratic form: exponent = pos^T @ sigma_inv @ pos, for each grid point.\n",
    "        # Hint: torch.matmul is also accessible as the operator @\n",
    "\n",
    "        # Evaluate the Gaussian function: f(x) = exp(-0.5 * exponent)\n",
    "\n",
    "        # Accumulate the weighted contribution of this Gaussian.\n",
    "        # Hint: alphas[i] is (r,g,b), while f_i is (res_y, res_x).\n",
    "        # When multiplying the two, make sure that they broadcast properly, e.g. by adding an empty (length-1) last dimension to f_i\n",
    "        \n",
    "        ########## \n",
    "        # BEGINNING OF YOUR CODE\n",
    "        ##########\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        ########## \n",
    "        # END OF YOUR CODE\n",
    "        ##########\n",
    "    \n",
    "    # replace possible NaNs with 0    \n",
    "    field = torch.nan_to_num(field)\n",
    "    \n",
    "    return field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 1: Optimize for Synthetic Ground Truth\n",
    "## Part 1.1. Generate Synthetic Ground Truth\n",
    "\n",
    "Let's test out the above functionalities by reconstructing a 2D Image from our Gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:24.425074Z",
     "start_time": "2025-03-13T01:20:24.244549Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DOMAIN = Domain2D(\n",
    "    x_dim=[-5.0, 5.0],  # virtual dimensions\n",
    "    y_dim=[-5.0, 5.0],\n",
    "    res_x=100,  # resolution\n",
    "    res_y=100\n",
    ")\n",
    "\n",
    "# Define the parameters in a dictionary.\n",
    "# Create torch tensors on the selected computing device (cpu/metal/cuda).\n",
    "target_params = {\n",
    "    # RGB colors\n",
    "    'alphas': torch.tensor([\n",
    "        [0.7, 0.1, 0.2], \n",
    "        [0.3, 0.8, 0.1]\n",
    "    ], device=DEVICE),\n",
    "    # X,Y coordinates\n",
    "    'centers': torch.tensor([\n",
    "        [-3.0, 1.5], \n",
    "        [1.5, 2.5]\n",
    "    ], device=DEVICE),\n",
    "    # Scales along local (X, Y)\n",
    "    'sigmas': torch.tensor([\n",
    "        [2.0, 1.5], \n",
    "        [1.5, 0.5]\n",
    "    ], device=DEVICE),\n",
    "    # Rotations\n",
    "    'thetas': torch.tensor([\n",
    "        0.2, 0.8\n",
    "    ], device=DEVICE)\n",
    "}\n",
    "\n",
    "# Reconstruct the 2D Gaussians on a 2D grid.\n",
    "# Note: the detach() function is needed, because we just want to generate some static \n",
    "#   synthetic target image data. If we didn't detach, then the computation that produced \n",
    "#   it would become part of PyTorch's computation graph when we calculate the loss later on. \n",
    "#   Or put simply: we just want a plain array of numbers.\n",
    "target_image_synthetic = reconstruct_image(target_params, domain=DOMAIN).detach()\n",
    "\n",
    "# Plot the target scene using the helper plotting function\n",
    "plot(data=target_image_synthetic, title=\"Synthetic test image\", domain=DOMAIN, figsize=(3,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 1.2. Initial random Gaussian parameters for the optimization\n",
    "\n",
    "Now we run a simple experiment: let's forget that the above \"ground truth image\" came from our predefined Gaussians. Can we find a set of Gaussian parameters that describe the same image?\n",
    "\n",
    "Let's generate a random set of Gaussian parameters, and look at what that gives us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:24.441923Z",
     "start_time": "2025-03-13T01:20:24.425229Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 20  # Number of Gaussians\n",
    "\n",
    "# Collect the parameters we want to optimize in a dictionary.\n",
    "# Feel free to play around with the random initialization!\n",
    "params_opt_synthetic = {\n",
    "    # get random RGB color for N gaussian\n",
    "    'alphas': nn.Parameter(torch.tensor(\n",
    "        [[random.random() for _ in range(3)] for _ in range(N)], \n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "    # positions: scatter N random gaussians in our domain\n",
    "    'centers': nn.Parameter(torch.tensor(\n",
    "        [[random.uniform(*DOMAIN.x_dim), random.uniform(*DOMAIN.y_dim)] for _ in range(N)], \n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "    # Scales along local (X, Y). Start out with isotropic gaussian\n",
    "    'sigmas': nn.Parameter(torch.tensor(\n",
    "        [[1.5, 1.5] for _ in range(N)], \n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "    # Rotations\n",
    "    'thetas': nn.Parameter(torch.tensor(\n",
    "        [0.0]*N, # or for random rotation: np.random.rand() * 2 * np.pi\n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:24.538625Z",
     "start_time": "2025-03-13T01:20:24.436005Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting initial gaussians\n",
    "initial_image = reconstruct_image(\n",
    "    params_opt_synthetic, \n",
    "    domain=DOMAIN\n",
    ")\n",
    "\n",
    "plot(\n",
    "    data=[target_image_synthetic, initial_image, initial_image],\n",
    "    title=[\"Target Image\", \"Initial Gaussians\", \"\"],\n",
    "    outline_params=[None, None, params_opt_synthetic],\n",
    "    extent=DOMAIN.get_extent(),\n",
    "    figsize=(7,10)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.3: Customized Gaussian Optimization\n",
    "\n",
    "Come up with a more fun, complex \"synthetic\" target image by modifying our initial gaussian parameters in Part 1.1. Run Part 1 with your new \"synthetic\" image and save the results. Feel free to change the number of Gaussians, just make sure to have the same number of colors, positions, scales, and rotations defined in each tensor (i.e. match their first dimension). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## REFLECTION QUESTION 1.\n",
    "- You might see a white blob where Gaussians are overlapping, instead of some nice colors.\n",
    "- Why is this happening in our model?\n",
    "- How could we improve this? Is there an easy fix?\n",
    "\n",
    "Hint: what's the difference between our 2D Gaussians and the z-index-based alpha blending we looked at in class?\n",
    "\n",
    "(YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 1.3. Optimization\n",
    "\n",
    "Now let's tweak our initial Gaussians. We would like the image reconstructed from them to be the same as our ground truth image $\\textbf{I}$. Calling our set of Gaussian parameters $\\xi$ (containing alphas, centers, sigmas, and thetas), we can quantify this in a scalar-valued loss function:\n",
    " \n",
    "$$\n",
    "    \\mathcal{L}(\\textbf{I}, \\xi) = \n",
    "    \\sum_{\\text{pixels \\textbf{p}} \\in \\text{\\textbf{I}}} \n",
    "        ||\n",
    "            \\boldsymbol{I}(\\boldsymbol{p}) - \\sum_{i}^N \\boldsymbol{\\alpha}_i f_i(\\boldsymbol{p}; \\xi_i)\n",
    "        ||,\n",
    "$$\n",
    "\n",
    "where $f_i(\\cdot;\\xi_i)$ simply denotes that we are using the $i$th Gaussian parameters.\n",
    "\n",
    "### Part 1.3.1 Initialize the optimizer\n",
    "Initialize the learning rate, optimizer, and loss function for Gaussian optimization.\n",
    "\n",
    "For this notebook, both $L_1$ and $L_2$ losses work fine. In the original 3DGS paper, they add together a D-SSIM loss with a weight of $0.2$ and an $L_1$ loss with a weight of $0.8$ to get their scalar loss.\n",
    "\n",
    "To find Gaussian parameters $\\xi$ that minimize this loss function, we use an Adam optimizer that iteratively steps towards the gradient of the loss w.r.t. the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:25.111348Z",
     "start_time": "2025-03-13T01:20:24.539423Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_keys = ['alphas', 'centers', 'sigmas', 'thetas']  # Note: params_opt.keys() is unordered.\n",
    "params_dict_for_optimizer = [{'params': params_opt_synthetic[p], 'name': p} for p in params_keys]\n",
    "# Note: this is the same as:\n",
    "# params_dict_for_optimizer = [\n",
    "#     {'params': params_opt_synthetic['alphas'], 'name': 'alphas'},\n",
    "#     {'params': params_opt_synthetic['centers'], 'name': 'centers'},\n",
    "#     {'params': params_opt_synthetic['sigmas'], 'name': 'sigmas'},\n",
    "#     {'params': params_opt_synthetic['thetas'], 'name': 'thetas'}\n",
    "# ]\n",
    "\n",
    "# We can also set per-parameter-group learning rates beyond the default learning rate below. \n",
    "# We can use this for freezing a given parameter group (e.g. leave particles in the same position).\n",
    "# For more details on setting up and using the optimizer: https://pytorch.org/docs/stable/optim.html\n",
    "# lr_dict = {'alphas': 0.01, 'centers': 0.2, 'sigmas': 0.0, 'thetas': 0.0}\n",
    "# for i, param_key in enumerate(params_keys):\n",
    "#     if param_key in lr_dict:\n",
    "#         params_dict_for_optimizer[i]['lr'] = lr_dict[param_key]\n",
    "\n",
    "\n",
    "# Define initial default learning rate\n",
    "lr = None\n",
    "########## \n",
    "# BEGINNING OF YOUR CODE\n",
    "##########\n",
    "\n",
    "\n",
    "########## \n",
    "# END OF YOUR CODE\n",
    "##########\n",
    "\n",
    "\n",
    "# Initialize an Adam optimizer\n",
    "# See: https://pytorch.org/docs/stable/generated/torch.optim.Adam.html\n",
    "optimizer = None\n",
    "########## \n",
    "# BEGINNING OF YOUR CODE\n",
    "##########\n",
    "\n",
    "\n",
    "########## \n",
    "# END OF YOUR CODE\n",
    "##########\n",
    "\n",
    "# Define the loss function we want to use in the optimization loop below\n",
    "def loss_function(prediction, target):\n",
    "    # Create a criterion, such as an L1 or L2 loss. You can also experiment with adding an SSIM loss.\n",
    "    # Hint: sticking with a simple L1 loss works fine perfect for this assignment.\n",
    "    \n",
    "    loss = None\n",
    "    \n",
    "    ##########\n",
    "    # BEGINNING OF YOUR CODE\n",
    "    ##########\n",
    "    \n",
    "    \n",
    "    ########## \n",
    "    # END OF YOUR CODE\n",
    "    ##########\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Part 1.3.2 Optimization loop\n",
    "\n",
    "Implement the optimization loop by following the steps outlined in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:40.369472Z",
     "start_time": "2025-03-13T01:20:25.113194Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_save_interval = 1  # Whether to same image\n",
    "num_epochs = 200\n",
    "display_plots = False  # Whether to plot in the notebook. Useful for not cluttering the notebook.\n",
    "save_plots = True  # Whether to write out images into a folder.\n",
    "\n",
    "if save_plots:\n",
    "    # Set the output folder to be the current time, and restart naming of the file names\n",
    "    initialize_file_names()\n",
    "    print(f\"Starting optimization. Outputting results into folder `{CURRENT_SCENE_FOLDER}`.\")\n",
    "else:\n",
    "    print(f\"Starting optimization without saving the results into file.\")\n",
    "    \n",
    "timer = Timer()\n",
    "\n",
    "# Keep track of lost history\n",
    "loss_trajectory = []\n",
    "\n",
    "epoch_progress_bar = tqdm(range(num_epochs))\n",
    "for epoch in epoch_progress_bar:\n",
    "    # Implement the optimization loop.\n",
    "    # (1) Forward pass, i.e. combining Gaussians into an image\n",
    "    # (2) Calculate and save current loss between output and target\n",
    "    #      Hint: don't forget to detach, bring to the cpu and convert to numpy before appending to the loss_trajectory.\n",
    "    # (3) Zero out gradients before running backward pass\n",
    "    # (4) Run backward pass: compute gradient of the loss (w.r.t. gaussian parameters)\n",
    "    # (5) Perform an optimization epoch (i.e. update gaussian parameters) by stepping the optimizer\n",
    "    # For details, see: https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "\n",
    "    ##########\n",
    "    # BEGINNING OF YOUR CODE\n",
    "    ##########\n",
    "    \n",
    "    \n",
    "    ##########\n",
    "    # END OF YOUR CODE\n",
    "    ##########\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # We don't want gradient calculation for this part.\n",
    "        # Note: Densification and Pruning could be done here by removing Gaussians\n",
    "        #       that are too small/stretched/out of bounds/etc,\n",
    "        #       and duplicating Gaussians based on their positional gradient.\n",
    "\n",
    "        # Optionally display/save image\n",
    "        if display_plots or save_plots:\n",
    "            if epoch % image_save_interval == 0:\n",
    "                fig = plot(\n",
    "                    data=[curr_image, curr_image, target_image_synthetic, loss_trajectory],\n",
    "                    outline_params=[None, params_opt_synthetic, None, None],\n",
    "                    title=[\n",
    "                        f\"Optim at epoch {epoch}\",\n",
    "                        f\"Gaussians (N={N})\",\n",
    "                        f\"Target image\",\n",
    "                        f\"Loss history\"\n",
    "                    ],\n",
    "                    domain=DOMAIN,\n",
    "                    show_plot=display_plots  # Optionally, don't clutter the notebook with showing the plot here.\n",
    "                )\n",
    "            if save_plots:\n",
    "                # Save plot to file as {curr_date}/{epoch}.jpg\n",
    "                save_fig_to_file(fig)\n",
    "            plt.close(fig)  # close the current figure\n",
    "\n",
    "        # Print out optimization details\n",
    "        progress_text = (\n",
    "            f\"Step {epoch}, \"\n",
    "            f\"Loss: {curr_loss.item()}, \"\n",
    "            f\"{timer.get_elapsed_time()}, \"\n",
    "            f\"N = {N}\"\n",
    "        )\n",
    "        \n",
    "        epoch_progress_bar.set_description(progress_text)\n",
    "\n",
    "        # You can try experimenting with a learning rate scheduler.\n",
    "        # In the simplest case, you can decrease the learning rate\n",
    "        # at some predefined intervals.\n",
    "        # if epoch % 800 == 0 and epoch > 0:\n",
    "        #     for param_group in self.optimizer.param_groups:\n",
    "        #         param_group['lr'] *= 0.5\n",
    "        #         print(f\"lr: {param_group['lr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Part 1.3.3 Plotting final result\n",
    "\n",
    "Turn in the image/video of your Gaussian optimization for your customized \"synthetic\" image by running the methods in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:42.503873Z",
     "start_time": "2025-03-13T01:20:42.306610Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_image = reconstruct_image(params_opt_synthetic, domain=DOMAIN)\n",
    "\n",
    "# Plotting final result\n",
    "plot(\n",
    "    data=[curr_image, curr_image, target_image_synthetic],\n",
    "    outline_params=[None, params_opt_synthetic, None],\n",
    "    title=[\n",
    "        f\"Result of optimization\",\n",
    "        f\"Gaussians (N={N})\",\n",
    "        f\"Target image\"\n",
    "    ],\n",
    "    domain=DOMAIN,\n",
    "    figsize=(10,6)\n",
    ")\n",
    "\n",
    "print(f\"Final params: {params_opt_synthetic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:45.271971Z",
     "start_time": "2025-03-13T01:20:45.212671Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write out the final params into a json data file:\n",
    "gaussians_to_json_file(\"optimized-params-synthetic.json\", params=params_opt_synthetic, domain=DOMAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:46.991955Z",
     "start_time": "2025-03-13T01:20:46.632195Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note: you can ignore the \"Corrupt JPEG data\" warnings if you see any. The video should still render properly.\n",
    "assemble_video(CURRENT_SCENE_FOLDER, str(\"anim-synthetic.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:47.808815Z",
     "start_time": "2025-03-13T01:20:47.787644Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# When running the notebook on Google Colab, we can directly show a video, but for some reason it sometimes requires an extra ffmpeg conversion.  \n",
    "if IN_COLAB:\n",
    "    from IPython.display import Video\n",
    "    \n",
    "    !ffmpeg -i anim-synthetic.mp4 -vcodec libx264 anim-synthetic-convert-out.mp4 -loglevel error -y\n",
    "    display(Video(\"anim-synthetic-convert-out.mp4\", embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 2: Optimize for Target Image\n",
    "\n",
    "In the second part of this notebook, we want to find Gaussian parameters that match an actual image. The process will be essentially the same as in Part 1, but you might need to tune some hyperparameters for the best result, such as the number of iterations, learning rate, number of Gaussians, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.1 Load target image  \n",
    "\n",
    "In this section, we have our sample target image of the Mona Lisa that will be loaded in this section. When you get to the creative expression section, you can modify this to use your creative target image instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:20:54.172767Z",
     "start_time": "2025-03-13T01:20:54.145488Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_input_image_as_torch_tensor(filename: str):\n",
    "    full_filename = DATA_FOLDER / filename\n",
    "    # Erase alpha channel ([:,:,0:3])\n",
    "    image_np = np.array(plt.imread(full_filename)[:, :, 0:3])\n",
    "\n",
    "    # transpose, and upside-down image to match 'xy' indexing of our meshgrid\n",
    "    # image_np = np.transpose(image_np, (1, 0, 2))  # Swapping height and width\n",
    "    image_np = np.flipud(image_np)  # Flipping upside down\n",
    "\n",
    "    image_torch = torch.tensor(image_np.copy(), requires_grad=False, device=DEVICE)\n",
    "\n",
    "    return image_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:21:01.540986Z",
     "start_time": "2025-03-13T01:21:01.487651Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the target input image as a torch tensor (requires_grad = False)\n",
    "# Expected in the `data` folder.\n",
    "file_name = \"mona-lisa.png\"\n",
    "target_image: torch.Tensor = get_input_image_as_torch_tensor(file_name)\n",
    "\n",
    "# Plot\n",
    "plot(target_image, \"Target Image\", (4, 3))\n",
    "\n",
    "# Same as target image pixel dimensions\n",
    "RES_X = target_image.shape[1]\n",
    "RES_Y = target_image.shape[0]\n",
    "x_to_y_ratio = float(RES_X) / float(RES_Y)\n",
    "\n",
    "X_DIM = (-5.0, 5.0)\n",
    "Y_DIM = (X_DIM[0]/x_to_y_ratio, X_DIM[1]/x_to_y_ratio)\n",
    "\n",
    "# New Domain\n",
    "DOMAIN = Domain2D(x_dim=X_DIM, y_dim=Y_DIM, res_x=RES_X, res_y=RES_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 2.2. Initial random Gaussian parameters for the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:33:20.740209Z",
     "start_time": "2025-03-13T01:33:20.703952Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 100  # Number of Gaussians\n",
    "\n",
    "# Collect the parameters we want to optimize in a dictionary\n",
    "params_opt_image = {\n",
    "    # get random RGB color for N gaussian\n",
    "    'alphas': nn.Parameter(torch.tensor(\n",
    "        [[random.random() for _ in range(3)] for _ in range(N)], \n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "    # positions: scatter N random gaussians in our domain\n",
    "    'centers': nn.Parameter(torch.tensor(\n",
    "        [[random.uniform(*DOMAIN.x_dim), random.uniform(*DOMAIN.y_dim)] for _ in range(N)], \n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "    # Scales along local (X, Y). Start out with isotropic gaussian\n",
    "    'sigmas': nn.Parameter(torch.tensor(\n",
    "        [[0.3, 0.3] for _ in range(N)], \n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "    # Rotations\n",
    "    'thetas': nn.Parameter(torch.tensor(\n",
    "        [0.0]*N, # or for random rotation: np.random.rand() * 2 * np.pi\n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:33:23.090587Z",
     "start_time": "2025-03-13T01:33:22.158685Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting initial gaussians\n",
    "initial_image = reconstruct_image(\n",
    "    params_opt_image, \n",
    "    domain=DOMAIN\n",
    ")\n",
    "\n",
    "plot(\n",
    "    data=[target_image, initial_image, initial_image],\n",
    "    title=[\"Target Image\", \"Initial Gaussians\", \"\"],\n",
    "    outline_params=[None, None, params_opt_image],\n",
    "    extent=DOMAIN.get_extent(),\n",
    "    figsize=(7,10)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 2.3. Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Part 2.3.1 Initialize the optimizer\n",
    "\n",
    "SImilar to the previous optimization section, initialize the learning rate, optimizer, and loss function for Gaussian optimization.\n",
    "\n",
    "For this notebook, both $L_1$ and $L_2$ losses work fine. In the original 3DGS paper, they add together a D-SSIM loss with a weight of $0.2$ and an $L_1$ loss with a weight of $0.8$ to get their scalar loss.\n",
    "\n",
    "To find Gaussian parameters $\\xi$ that minimize this loss function, we use an Adam optimizer that iteratively steps towards the gradient of the loss w.r.t. the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:33:29.375600Z",
     "start_time": "2025-03-13T01:33:29.345991Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set per-parameter-group learning rates beyond the default learning rate below. \n",
    "# We can use this for freezing a given parameter group (e.g. leave particles in the same position).\n",
    "# For more details on setting up and using the optimizer: https://pytorch.org/docs/stable/optim.html\n",
    "params_dict_for_optimizer = [\n",
    "     {'params': params_opt_image['alphas'], 'name': 'alphas'},\n",
    "     {'params': params_opt_image['centers'], 'name': 'centers'},\n",
    "     {'params': params_opt_image['sigmas'], 'name': 'sigmas'},\n",
    "     {'params': params_opt_image['thetas'], 'name': 'thetas'}\n",
    "]\n",
    "\n",
    "# (1) Initialize a NEW adam optimizer with the `params_opt_image` parameters, and optionally define a new loss function.\n",
    "\n",
    "#########\n",
    "# BEGINNING OF YOUR CODE\n",
    "#########\n",
    "\n",
    "\n",
    "\n",
    "#########\n",
    "# END OF YOUR CODE\n",
    "#########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Part 2.3.2. Optimization loop\n",
    "\n",
    "Similarly to Part 1.3.2, implement the optimization loop by following the steps outlined in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:36:16.101327Z",
     "start_time": "2025-03-13T01:33:35.671606Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Intervals during optimization\n",
    "image_save_interval = 1\n",
    "num_epochs = 200  # number of epochs to optimize for\n",
    "display_plots = False  # For not cluttering the notebook\n",
    "save_plots = True  # Writing out images into a folder\n",
    "\n",
    "if save_plots:\n",
    "    # Set the output folder to be the current time, and restart naming of the file names\n",
    "    initialize_file_names()\n",
    "    print(f\"Starting optimization. Outputting results into folder `{CURRENT_SCENE_FOLDER}`.\")\n",
    "else:\n",
    "    print(f\"Starting optimization without saving the results into file.\")\n",
    "    \n",
    "timer = Timer()\n",
    "\n",
    "# Keep track of lost history\n",
    "loss_trajectory = []\n",
    "\n",
    "epoch_progress_bar = tqdm(range(num_epochs))\n",
    "for epoch in epoch_progress_bar:\n",
    "    # Forward pass, i.e. combining Gaussians into an image\n",
    "    # Calculate and save current loss between output and target\n",
    "    # Zero out gradients before running backward pass\n",
    "    # Compute gradient of the loss (w.r.t. gaussian parameters)\n",
    "    # Perform an optimization epoch (i.e. update gaussian parameters)\n",
    "\n",
    "    #############################################\n",
    "    # BEGINNING OF YOUR CODE\n",
    "    #############################################\n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    # END OF YOUR CODE\n",
    "    #############################################\n",
    "\n",
    "    for key in params_opt_image:\n",
    "        torch.nan_to_num(params_opt_image[key])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Optionally display/save image\n",
    "        if display_plots or save_plots:\n",
    "            if epoch % image_save_interval == 0:\n",
    "                fig = plot(\n",
    "                    data=[curr_image, curr_image, target_image, loss_trajectory],\n",
    "                    outline_params=[None, params_opt_image, None, None],\n",
    "                    title=[\n",
    "                        f\"Optim at epoch {epoch}\",\n",
    "                        f\"Gaussians (N={N})\",\n",
    "                        f\"Target image\",\n",
    "                        f\"Loss history\"\n",
    "                    ],\n",
    "                    domain=DOMAIN,\n",
    "                    show_plot=display_plots  # Optionally, don't clutter the notebook with showing the plot here.\n",
    "                )\n",
    "            if save_plots:\n",
    "                # Save plot to file as {curr_date}/{epoch}.jpg\n",
    "                save_fig_to_file(fig)\n",
    "            plt.close(fig)  # close the current figure\n",
    "\n",
    "        # Print out optimization details\n",
    "        progress_text = (\n",
    "            f\"Step {epoch}, \"\n",
    "            f\"Loss: {curr_loss.item()}, \"\n",
    "            f\"{timer.get_elapsed_time()}, \"\n",
    "            f\"N = {N}\"\n",
    "        )\n",
    "        \n",
    "        epoch_progress_bar.set_description(progress_text)\n",
    "\n",
    "        # You can experiment with changing the learning rate here\n",
    "        # if epoch % 800 == 0 and epoch > 0:\n",
    "        #     for param_group in self.optimizer.param_groups:\n",
    "        #         param_group['lr'] *= 0.5\n",
    "        #         print(f\"lr: {param_group['lr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Part 2.3.3. Plotting final result\n",
    "\n",
    "Create the image/video of your Gaussian optimization for the Mona Lisa target image by running the methods in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:36:18.834458Z",
     "start_time": "2025-03-13T01:36:17.457536Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_image = reconstruct_image(params_opt_image, domain=DOMAIN)\n",
    "\n",
    "# Plotting final result\n",
    "plot(\n",
    "    data=[curr_image, curr_image, target_image],\n",
    "    outline_params=[None, params_opt_image, None],\n",
    "    title=[\n",
    "        f\"Result of optimization\",\n",
    "        f\"Gaussians (N={N})\",\n",
    "        f\"Target image\"\n",
    "    ],\n",
    "    domain=DOMAIN,\n",
    "    figsize=(10,6)\n",
    ")\n",
    "\n",
    "print(f\"Final params: {params_opt_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:36:22.445612Z",
     "start_time": "2025-03-13T01:36:21.778811Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write out the final params into a json data file:\n",
    "gaussians_to_json_file(\"optimized-params-image.json\", params=params_opt_image, domain=DOMAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:36:24.096027Z",
     "start_time": "2025-03-13T01:36:23.519672Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assemble_video(CURRENT_SCENE_FOLDER, str(\"anim-image.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:36:24.108893Z",
     "start_time": "2025-03-13T01:36:24.097221Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# When running the notebook on Google Colab, we can directly show a video, but for some reason it sometimes requires an extra ffmpeg conversion. Thanks to Amrutha Srikanth for this fix.  \n",
    "if IN_COLAB:\n",
    "    from IPython.display import Video\n",
    "    \n",
    "    !ffmpeg -i anim-image.mp4 -vcodec libx264 anim-image-convert-out.mp4 -loglevel error -y\n",
    "    display(Video(\"anim-image-convert-out.mp4\", embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 2.4. Exporting to a GLSL shader\n",
    "\n",
    "You can export your final Gaussian parameters into a GLSL shader by running this code and copying the parameters to the highlighted area in the GLSL Shader. \n",
    "\n",
    "(Thanks to [Molin Deng](https://molin7.vercel.app/home) for the code.)\n",
    "\n",
    "For submitting the CG in the AI Era homework, see further instructions on [https://cgai-gatech.vercel.app/](https://cgai-gatech.vercel.app/).\n",
    "\n",
    "For inspiration, here are a couple of cool examples on shadertoy of what you could do with your 2D Gaussian image:\n",
    "- [https://www.shadertoy.com/view/tflXRB](https://www.shadertoy.com/view/tflXRB)\n",
    "- [https://www.shadertoy.com/view/dtSfDD](https://www.shadertoy.com/view/dtSfDD)\n",
    "- [https://www.shadertoy.com/view/MdfGDH](https://www.shadertoy.com/view/MdfGDH)\n",
    "- [https://www.shadertoy.com/view/4df3D8](https://www.shadertoy.com/view/4df3D8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T01:36:26.753324Z",
     "start_time": "2025-03-13T01:36:26.719616Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_params_to_glsl(domain, params):\n",
    "    \"\"\"\n",
    "    Converts Gaussian parameters directly to GLSL shader code arrays\n",
    "    without using packed encoding.\n",
    "    \n",
    "    Args:\n",
    "        params: Dictionary containing 'alphas', 'centers', 'sigmas', and 'thetas'\n",
    "        \n",
    "    Returns:\n",
    "        String containing GLSL code for defining the Gaussian arrays\n",
    "    \"\"\"\n",
    "    x_min, x_max = domain.x_dim\n",
    "    y_min, y_max = domain.y_dim\n",
    "    # Extract parameters and convert to numpy\n",
    "    alphas = params['alphas'].detach().cpu().numpy()\n",
    "    centers = params['centers'].detach().cpu().numpy()\n",
    "    sigmas = params['sigmas'].detach().cpu().numpy()\n",
    "    thetas = params['thetas'].detach().cpu().numpy()\n",
    "    \n",
    "    # Get number of Gaussians\n",
    "    num_gaussians = len(centers)\n",
    "    \n",
    "    # Get maximum sigma value for scale reference\n",
    "    max_sigma = float(np.max(sigmas))\n",
    "    \n",
    "    # Start building GLSL code\n",
    "    glsl_code = f\"\"\"\n",
    "// Number of Gaussians\n",
    "const int NUM_GAUSSIANS = {num_gaussians};\n",
    "// Dimensions [x_min, x_max, y_min, y_max]\n",
    "float dim[4] = float[4]({x_min},{x_max},{y_min},{y_max});\n",
    "// Centers (x, y coordinates)\n",
    "vec2 gauss_centers[NUM_GAUSSIANS] = vec2[NUM_GAUSSIANS](\"\"\"\n",
    "    \n",
    "    # Add center coordinates\n",
    "    center_lines = []\n",
    "    for i in range(num_gaussians):\n",
    "        center_lines.append(f\"vec2({centers[i, 0]:.2f}, {centers[i, 1]:.2f})\")\n",
    "    glsl_code += \",\".join(center_lines) + \");\\n\"\n",
    "    \n",
    "    # Add sigmas (scales)\n",
    "    glsl_code += \"// Sigmas (scales)\\nvec2 gauss_sigmas[NUM_GAUSSIANS] = vec2[NUM_GAUSSIANS](\"\n",
    "    sigma_lines = []\n",
    "    for i in range(num_gaussians):\n",
    "        sigma_lines.append(f\"vec2({sigmas[i, 0]:.2f}, {sigmas[i, 1]:.2f})\")\n",
    "    glsl_code += \",\".join(sigma_lines) + \");\\n\"\n",
    "    \n",
    "    # Add rotation angles (thetas)\n",
    "    glsl_code += \"// Rotation angles (thetas)\\nfloat gauss_thetas[NUM_GAUSSIANS] = float[NUM_GAUSSIANS](\"\n",
    "    theta_lines = []\n",
    "    for i in range(num_gaussians):\n",
    "        theta_lines.append(f\"{thetas[i]:.2f}\")\n",
    "    glsl_code += \",\".join(theta_lines) + \");\\n\"\n",
    "    \n",
    "    # Add colors (alphas)\n",
    "    glsl_code += \"// Colors (RGB)\\nvec3 gauss_colors[NUM_GAUSSIANS] = vec3[NUM_GAUSSIANS](\"\n",
    "    color_lines = []\n",
    "    for i in range(num_gaussians):\n",
    "        color_lines.append(f\"vec3({alphas[i, 0]:.2f}, {alphas[i, 1]:.2f}, {alphas[i, 2]:.2f})\")\n",
    "    glsl_code += \",\".join(color_lines) + \");\\n\\n\"\n",
    "    \n",
    "    return glsl_code\n",
    "\n",
    "print(convert_params_to_glsl(DOMAIN, params_opt_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Render Optimized Gaussians in GLSL Shader\n",
    "\n",
    "In the final part of this notebook, you must copy your generated Gaussian parameters for the target image and fill in the gaps in the fragment.glsl file to accurately show the list of gaussians. \n",
    "\n",
    "Your code will include building the inverse covariance matrix needed to place Gaussians in the scene and calculating the contribution of each Gaussian to the overall image field. \n",
    "\n",
    "This way, you can see your target gaussian splatting image animation on the class website.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creative Expression\n",
    "\n",
    "Find or create an interesting target image and replace our sample image (the Mona Lisa) with it in the loading code block (Part 2.1). Run Part 2 with your new target image and save the results. Feel free to change the number of Gaussians, just make sure to have the same number of colors, positions, scales, and rotations defined in each tensor (i.e. match their first dimension). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Acknowledgments\n",
    "\n",
    "This implementation is based on [https://github.com/bobarna/tiny-2d-gaussian-splatting](https://github.com/bobarna/tiny-2d-gaussian-splatting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
