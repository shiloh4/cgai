{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-2P-ZYctBUZ"
   },
   "source": [
    "# **A Simplified NeRF**\n",
    "\n",
    "This notebook implements a simplified NeRF (Neural Radiance Fields) model using PyTorch.\n",
    "\n",
    "## Steps:\n",
    "1. Install and import necessary libraries, and check device\n",
    "2. Define dataset class\n",
    "3. Define NeRF model **(your implementation goes here)**\n",
    "4. Set hyperparameters and train NeRF model\n",
    "5. Visualize training results\n",
    "6. Serialize and render\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2915,
     "status": "ok",
     "timestamp": 1739326949851,
     "user": {
      "displayName": "Sinan Wang",
      "userId": "07288447329123164358"
     },
     "user_tz": 300
    },
    "id": "install_libraries",
    "outputId": "3759a9b1-dfa4-4d01-ef8a-126651ae48a4"
   },
   "outputs": [],
   "source": [
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8926,
     "status": "ok",
     "timestamp": 1739326958775,
     "user": {
      "displayName": "Sinan Wang",
      "userId": "07288447329123164358"
     },
     "user_tz": 300
    },
    "id": "import_libraries",
    "outputId": "7049e502-ae1f-4c09-d992-f0efc4b26d65"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Current device:\", device)\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 175,
     "status": "ok",
     "timestamp": 1739326997642,
     "user": {
      "displayName": "Sinan Wang",
      "userId": "07288447329123164358"
     },
     "user_tz": 300
    },
    "id": "load_data",
    "outputId": "e48d6519-02e0-4d3f-cd5b-8f89842830d5"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class NeRFDataset(Dataset):\n",
    "    \"\"\"\n",
    "    NeRF data loading.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, device='cuda'):\n",
    "        data = np.load(data_path)\n",
    "\n",
    "        self.images = torch.from_numpy(data['images'].astype(np.float32))[..., :3].to(device)   # Shape: [N, H, W, 3]\n",
    "        self.poses = torch.from_numpy(data['poses'].astype(np.float32)).to(device)              # Shape: [N, 4, 4]\n",
    "        self.focal = torch.tensor(data['focal'], dtype=torch.float32, device=device)            # Scalar focal length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.poses[idx], self.focal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define NeRF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 172,
     "status": "ok",
     "timestamp": 1739327007518,
     "user": {
      "displayName": "Sinan Wang",
      "userId": "07288447329123164358"
     },
     "user_tz": 300
    },
    "id": "nerf_model"
   },
   "outputs": [],
   "source": [
    "class NeRFNetwork(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    NeRF Model: A Multi-Layer Perceptron (MLP) with integrated ray generation,\n",
    "    volumetric rendering, and training functionality.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim=64, n_freqs=6):\n",
    "        super(NeRFNetwork, self).__init__()\n",
    "        self.n_freqs = n_freqs  # Positional encoding frequencies\n",
    "        in_channels = 3 + 3 * 2 * n_freqs  # Input: 3D position + encoded features\n",
    "        self.layer1 = torch.nn.Linear(in_channels, hidden_dim)\n",
    "        self.layer2 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.output_layer = torch.nn.Linear(hidden_dim, 4)  # Output: [R, G, B, sigma]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        return self.output_layer(x)\n",
    "\n",
    "    def generate_rays(self, H, W, focal, cam2world):\n",
    "        # get ray origin and dir from cam\n",
    "        i, j = torch.meshgrid(\n",
    "            torch.linspace(0, W-1, W, device=device),\n",
    "            torch.linspace(0, H-1, H, device=device),\n",
    "            indexing='xy'\n",
    "        )\n",
    "        dirs = torch.stack([(i - W * 0.5) / focal, -(j - H * 0.5) / focal, -torch.ones_like(i)], dim=-1)\n",
    "        rays_d = torch.einsum('ij,hwj->hwi', cam2world[:3, :3], dirs)\n",
    "        rays_o = cam2world[:3, -1].expand_as(rays_d)\n",
    "        return rays_o, rays_d\n",
    "\n",
    "    def positional_encoding(self, x, n_freqs=6):\n",
    "        \"\"\"\n",
    "        Apply positional encoding to input coordinates. The final dimension should be 3 + 3 * 2 * n_freqs.\n",
    "        IMPORTANT: When passing `x` into a function, always use PyTorch operations \n",
    "        to ensure compatibility with autograd.\n",
    "\n",
    "        In this function, you are tasked to work on the following 2 steps:\n",
    "        (1) Apply `n_freqs` frequency transformations using PyTorch sine and cosine functions.\n",
    "        (2) Concatenate all encoded features into a single pytorch tensor.\n",
    "        \"\"\"\n",
    "        # Include the original input `x` as part of the encoding.\n",
    "        encodings = [x]\n",
    "\n",
    "        # your implementation starts\n",
    "\n",
    "        # your implementation ends\n",
    "\n",
    "        # Return the encoded position\n",
    "        return encoded_pos\n",
    "\n",
    "    # volume rendering\n",
    "    def vol_render(self, rays_o, rays_d, near, far, N_samples):\n",
    "        \"\"\"\n",
    "        Render rays via volume rendering.\n",
    "        IMPORTANT: You should use pytorch functions to implement this.\n",
    "\n",
    "        In this function, you are tasked to work on the following 4 steps:\n",
    "        (1) Extract density (`sigma`) and color (`rgb`) from the network output.\n",
    "        (2) Apply a sigmoid activation to `rgb` to constrain it within [0,1], and use ReLU on `sigma` to ensure non-negative values.\n",
    "        (3) Compute distances between adjacent depth samples and apply volume rendering equations.\n",
    "        (4) Compute final pixel color (`rgb_map`) by summing along the ray.\n",
    "\n",
    "        Hint: you may want to use [pytorch cumulative product](https://pytorch.org/docs/stable/generated/torch.cumprod.html)\n",
    "\n",
    "        Recommendation: Since there are many tensor operations in this function, \n",
    "        **record and print the shape of each variable** while implementing, \n",
    "        and verify that they match expectations. This will help debug shape mismatches \n",
    "        and ensure correct broadcasting.\n",
    "        \"\"\"\n",
    "         # Partition [near, far] into N evenly-spaced bins (N+1 borders).\n",
    "        z_vals = torch.linspace(near, far, N_samples + 1, device=device)\n",
    "        z_vals = z_vals.expand(*rays_o.shape[:-1], N_samples + 1)\n",
    "        z_vals = 0.5 * (z_vals[..., :-1] + z_vals[..., 1:])\n",
    "        # Draw one sample uniformly at random from within each bin.\n",
    "        z_vals += torch.rand_like(z_vals) * ((far - near) / N_samples)\n",
    "        # Compute 3D positions of sampled points along the rays (ray_o + ray_d * z_vals) and apply `positional_encoding`.\n",
    "        points = rays_o[..., None, :] + rays_d[..., None, :] * z_vals[..., :, None]  # (H, W, N_samples, 3)\n",
    "        # Pass the encoded features through the network to obtain raw NeRF outputs.\n",
    "        raw = self.forward(self.positional_encoding(points.reshape(-1, 3), self.n_freqs)).reshape(*points.shape[:-1], 4) # first three is rgb, last is density\n",
    "\n",
    "        # your implementation starts\n",
    "\n",
    "        # your implementation ends\n",
    "\n",
    "        # Return the predicted image\n",
    "        return rgb_map\n",
    "\n",
    "\n",
    "    def train_step(self, pose_mat, target_img, focal, optimizer, H, W, near=2.0, far=6.0, n_samples=64):\n",
    "        \"\"\"\n",
    "        Performs one training step.\n",
    "\n",
    "        In this function, you are tasked to work on the following 4 steps:\n",
    "        (1) Generate ray origins (`rays_o`) and directions (`rays_d`) from camera parameters (post_mat and focal). Note that we have implemented this for you.\n",
    "        (2) Render the scene by performing volume rendering (the above function you just implemented) along the rays.\n",
    "        (3) Compute the mean squared error (MSE) loss between the rendered image and the ground truth (`target_img`).\n",
    "        (4) Perform backpropagation and update model weights using the optimizer.\n",
    "        \"\"\"\n",
    "        # your implementation starts\n",
    "\n",
    "        # your implementation ends\n",
    "\n",
    "        # Return the loss\n",
    "        return loss.item()\n",
    "\n",
    "    def test_step(self, test_pose, test_image, focal, H, W, near=2.0, far=6.0, n_samples=64):\n",
    "        \"\"\"\n",
    "        Performs a test step to evaluate the model.\n",
    "\n",
    "        In this function, you are tasked to work on the following 4 steps:\n",
    "        (1) Generate test rays (`rays_o`, `rays_d`) from the test camera pose. Note that we have implemented this for you.\n",
    "        (2) Perform volume rendering to obtain the predicted image.\n",
    "        (3) Compute the mean squared error (MSE) loss against the test image.\n",
    "        (4) Compute the peak signal-to-noise ratio (PSNR) as a quality metric, where PSNR = -10*log_10(MSELoss).\n",
    "        \"\"\"\n",
    "        # your implementation starts\n",
    "\n",
    "        # your implementation ends\n",
    "\n",
    "        # Return the predicted image and the PSNR\n",
    "        return test_rgb_map, test_psnr.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1739327008749,
     "user": {
      "displayName": "Sinan Wang",
      "userId": "07288447329123164358"
     },
     "user_tz": 300
    },
    "id": "K8uBcR-Ru_w_",
    "outputId": "b32ef2ef-314b-4d97-a71f-1a5aca1fee68"
   },
   "outputs": [],
   "source": [
    "# dataset path, change it for different datasets\n",
    "full_dataset = NeRFDataset(\"tiny_lego.npz\")\n",
    "\n",
    "# Split dataset: Use first 99 images for training, 100th image for testing\n",
    "train_dataset = torch.utils.data.Subset(full_dataset, range(99))\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_image, test_pose, focal_torch = full_dataset[99]\n",
    "\n",
    "# Get image dimensions\n",
    "H, W = test_image.shape[:2]\n",
    "print(\"Test image resolution:\", test_image.shape)\n",
    "\n",
    "# Default hyperparameters, feel free to change\n",
    "n_samples = 64        # Number of samples per ray\n",
    "num_iters = 10000     # Number of training iterations\n",
    "learning_rate = 5e-3  # Learning rate\n",
    "n_freqs = 6           # positional encoding frequency\n",
    "logging_freq = 1000   # Log output frequency (iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NeRF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "executionInfo": {
     "elapsed": 24616,
     "status": "error",
     "timestamp": 1739327034653,
     "user": {
      "displayName": "Sinan Wang",
      "userId": "07288447329123164358"
     },
     "user_tz": 300
    },
    "id": "train_model",
    "outputId": "d657fb7b-4254-4f8a-b69c-2e6770ffce5f"
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = NeRFNetwork(hidden_dim=64, n_freqs=n_freqs).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "psnr_log = []\n",
    "iter_log = []\n",
    "\n",
    "\n",
    "print(\"Starting NeRF Training...\")\n",
    "train_iter = cycle(train_loader) \n",
    "for i in tqdm(range(num_iters)):  # num_iters=10000\n",
    "    target_img, pose_mat, focal = next(train_iter)\n",
    "    loss = model.train_step(pose_mat.squeeze(0), target_img.squeeze(0), focal.squeeze(0), optimizer, H, W)\n",
    "    # Log training progress\n",
    "    if (i) % logging_freq == 0:\n",
    "        _, test_psnr = model.test_step(test_pose, test_image, focal_torch, H, W)\n",
    "        psnr_log.append(test_psnr)\n",
    "        iter_log.append(i)\n",
    "        print(f\"Iteration {i}: Training Loss={loss:.4f}, Test PSNR={test_psnr:.2f}\")\n",
    "print(\"Training Completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Rendered Test Image and PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1739326958922,
     "user": {
      "displayName": "Sinan Wang",
      "userId": "07288447329123164358"
     },
     "user_tz": 300
    },
    "id": "U2yCJi9pydQ3"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred_rgb, test_psnr = model.test_step(test_pose, test_image, focal_torch, H, W)\n",
    "\n",
    "\n",
    "# Convert tensors to NumPy arrays for visualization\n",
    "pred_rgb_np = pred_rgb.cpu().numpy()\n",
    "test_img_np = test_image.cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(test_img_np)\n",
    "plt.title(\"Ground Truth\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(pred_rgb_np)\n",
    "plt.title(\"NeRF Prediction\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(iter_log, psnr_log, label='PSNR')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"PSNR\")\n",
    "plt.title(\"PSNR Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1739326958922,
     "user": {
      "displayName": "Sinan Wang",
      "userId": "07288447329123164358"
     },
     "user_tz": 300
    },
    "id": "7EgYP4Dn2-xu"
   },
   "outputs": [],
   "source": [
    "# You may need to modify this function if you change the network structure too aggressively.\n",
    "import re\n",
    "\n",
    "def dump_data(t):\n",
    "    return t.detach().cpu().numpy()\n",
    "\n",
    "def fmt_float(x):\n",
    "    s = f\"{x:.2f}\"\n",
    "    s = re.sub(r\"\\b0\\.\", \".\", s)\n",
    "    return s\n",
    "\n",
    "def print_vec4(v):\n",
    "    vals = \",\".join(fmt_float(x) for x in v)\n",
    "    return f\"vec4({vals})\"\n",
    "\n",
    "def print_mat4(m):\n",
    "    mT = m.T\n",
    "    vals = []\n",
    "    for r in range(4):\n",
    "        for c in range(4):\n",
    "            vals.append(fmt_float(mT[r,c]))\n",
    "    return f\"mat4({','.join(vals)})\"\n",
    "\n",
    "def positional_encoding_glsl(n_freqs=6, varname=\"p\"):\n",
    "    lines = []\n",
    "\n",
    "    encode_vals = []\n",
    "    # 0) p.x, p.y, p.z\n",
    "    encode_vals.append(f\"{varname}.x\")\n",
    "    encode_vals.append(f\"{varname}.y\")\n",
    "    encode_vals.append(f\"{varname}.z\")\n",
    "    # 1) sin/cos\n",
    "    import math\n",
    "    for i in range(n_freqs):\n",
    "        freq = 2**i\n",
    "        # sin(freq * p.x), sin(freq * p.y), sin(freq * p.z)\n",
    "        encode_vals.append(f\"sin({fmt_float(freq)}*{varname}.x)\")\n",
    "        encode_vals.append(f\"sin({fmt_float(freq)}*{varname}.y)\")\n",
    "        encode_vals.append(f\"sin({fmt_float(freq)}*{varname}.z)\")\n",
    "        # cos(freq * p.x), cos(freq * p.y), cos(freq * p.z)\n",
    "        encode_vals.append(f\"cos({fmt_float(freq)}*{varname}.x)\")\n",
    "        encode_vals.append(f\"cos({fmt_float(freq)}*{varname}.y)\")\n",
    "        encode_vals.append(f\"cos({fmt_float(freq)}*{varname}.z)\")\n",
    "\n",
    "\n",
    "    num_chunks = (len(encode_vals) + 3)//4\n",
    "    for c in range(num_chunks):\n",
    "        start = c*4\n",
    "        end = start+4\n",
    "        subset = encode_vals[start:end]\n",
    "        if len(subset) < 4:\n",
    "            subset += [\"0.0\"]*(4 - len(subset))\n",
    "        line = f\"vec4 PE_{c} = vec4({','.join(subset)});\"\n",
    "        lines.append(line)\n",
    "\n",
    "    return lines, num_chunks\n",
    "\n",
    "def serialize_nerf_network(model, n_freqs=6, varname=\"f\"):\n",
    "    lines = []\n",
    "\n",
    "\n",
    "    pe_code, pe_chunks = positional_encoding_glsl(n_freqs=n_freqs, varname=\"p\")\n",
    "    lines.extend(pe_code)\n",
    "    lines.append(\"\")\n",
    "\n",
    "    input_dim = 4*pe_chunks\n",
    "\n",
    "\n",
    "    layer1 = model.layer1\n",
    "    w1 = dump_data(layer1.weight)  # shape: [hidden_dim, input_dim]\n",
    "    b1 = dump_data(layer1.bias)    # shape: [hidden_dim]\n",
    "    hidden_dim = w1.shape[0]\n",
    "\n",
    "\n",
    "    chunk0 = (hidden_dim+3)//4\n",
    "\n",
    "    for i in range(chunk0):\n",
    "        r0 = i*4\n",
    "        r1 = min(r0+4, hidden_dim)\n",
    "        size = r1-r0\n",
    "\n",
    "        w_sub = w1[r0:r1, :]  # shape=[size, input_dim]\n",
    "        b_sub = b1[r0:r1]\n",
    "        if size<4:\n",
    "            pad = 4-size\n",
    "            w_sub = np.pad(w_sub, ((0,pad),(0,0)), mode='constant')\n",
    "            b_sub = np.pad(b_sub, (0,pad), mode='constant')\n",
    "\n",
    "        line = f\"vec4 {varname}0_{i} = relu(\\n    \"\n",
    "        sum_terms = []\n",
    "        for j in range(pe_chunks):\n",
    "            c0 = j*4\n",
    "            c1 = c0+4\n",
    "            block = w_sub[:, c0:c1]  # shape=[4, 4]\n",
    "            col_size = block.shape[1]\n",
    "            if col_size<4:\n",
    "                block = np.pad(block, ((0,0),(0,4-col_size)), mode='constant')\n",
    "            m_str = print_mat4(block)\n",
    "            sum_terms.append(f\"{m_str} * PE_{j}\")\n",
    "        bias_str = print_vec4(b_sub)\n",
    "        line += \" +\\n    \".join(sum_terms)\n",
    "        line += f\" + {bias_str});\"\n",
    "        lines.append(line)\n",
    "\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # layer2\n",
    "    layer2 = model.layer2\n",
    "    w2 = dump_data(layer2.weight)  # [hidden_dim, hidden_dim]\n",
    "    b2 = dump_data(layer2.bias)\n",
    "    chunk1 = (layer2.out_features+3)//4\n",
    "\n",
    "    hidden_dim2 = w2.shape[0]\n",
    "    chunk1 = (hidden_dim2 +3)//4\n",
    "\n",
    "    for i in range(chunk1):\n",
    "        r0 = i*4\n",
    "        r1 = min(r0+4, hidden_dim2)\n",
    "        size = r1-r0\n",
    "\n",
    "        w_sub = w2[r0:r1, :]  # shape=[size, hidden_dim]\n",
    "        b_sub = b2[r0:r1]\n",
    "        if size<4:\n",
    "            pad = 4-size\n",
    "            w_sub = np.pad(w_sub, ((0,pad),(0,0)), mode='constant')\n",
    "            b_sub = np.pad(b_sub, (0,pad), mode='constant')\n",
    "\n",
    "        # \"vec4 f1_i = relu( sum_j mat4(...) * f0_j + bias );\"\n",
    "        line = f\"vec4 {varname}1_{i} = relu(\\n    \"\n",
    "        sum_terms = []\n",
    "        for j in range(chunk0):\n",
    "            c0 = j*4\n",
    "            c1 = c0+4\n",
    "            block = w_sub[:, c0:c1]\n",
    "            if block.shape[1]<4:\n",
    "                block = np.pad(block, ((0,0),(0,4-block.shape[1])), mode='constant')\n",
    "            m_str = print_mat4(block)\n",
    "            sum_terms.append(f\"{m_str} * {varname}0_{j}\")\n",
    "        bias_str = print_vec4(b_sub)\n",
    "        line += \" +\\n    \".join(sum_terms)\n",
    "        line += f\" + {bias_str});\"\n",
    "        lines.append(line)\n",
    "\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # output_layer( shape=[4, hidden_dim2] )\n",
    "    outlayer = model.output_layer\n",
    "    w3 = dump_data(outlayer.weight) # shape=[4, hidden_dim2]\n",
    "    b3 = dump_data(outlayer.bias)   # shape=[4]\n",
    "\n",
    "\n",
    "    out_lines = []\n",
    "    for o in range(4):\n",
    "        wrow = w3[o, :]  # [hidden_dim2]\n",
    "        expr = f\"float out{o} = \"\n",
    "        sum_terms = []\n",
    "        for j in range(chunk1):\n",
    "            c0 = j*4\n",
    "            c1 = c0+4\n",
    "            subvec = wrow[c0:c1]\n",
    "            if len(subvec)<4:\n",
    "                subvec = np.pad(subvec, (0,4-len(subvec)), mode='constant')\n",
    "            v4 = print_vec4(subvec)\n",
    "            sum_terms.append(f\"dot({varname}1_{j}, {v4})\")\n",
    "        expr += \" + \".join(sum_terms)\n",
    "        expr += f\" + {fmt_float(b3[o])};\"\n",
    "        out_lines.append(expr)\n",
    "\n",
    "    out_lines.append(\"return vec4(out0, out1, out2, out3);\")\n",
    "\n",
    "    lines.extend(out_lines)\n",
    "\n",
    "    glsl_code = (\n",
    "        \"vec4 queryNetwork(vec3 p){\\n\"\n",
    "    )\n",
    "    body_block = \"\\n\".join(\"    \" + l for l in lines)\n",
    "\n",
    "    glsl_code += body_block\n",
    "    glsl_code += \"\\n}\\n\"\n",
    "\n",
    "    return glsl_code\n",
    "\n",
    "code = serialize_nerf_network(model, n_freqs=n_freqs)\n",
    "filename = \"serialized_model.txt\"\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(code)\n",
    "print(\"Serialization done, results stored in \" + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "This implementation is based on the following works:  \n",
    "\n",
    "- [Tiny NeRF (Colab)](https://colab.research.google.com/github/bmild/nerf/blob/master/tiny_nerf.ipynb).  \n",
    "- [TinyNeRF](https://github.com/volunt4s/TinyNeRF-pytorch).  \n",
    "\n",
    "The dataset comes from the [Nerf Synthetic Dataset](https://www.kaggle.com/datasets/nguyenhung1903/nerf-synthetic-dataset)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
